{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler, SubsetRandomSampler\n",
    "import time\n",
    "import os\n",
    "import collections\n",
    "from efficientnet.model import EfficientNet\n",
    "from torchvision import transforms, models\n",
    "from efficientnet.utils import round_filters, efficientnet\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error, mean_absolute_error\n",
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, RandomRotate90, Normalize, Flip, OneOf, Compose, Resize, Transpose\n",
    ")\n",
    "from catalyst.contrib.schedulers import OneCycleLR, ReduceLROnPlateau, StepLR, MultiStepLR\n",
    "from catalyst.dl.experiment import SupervisedExperiment\n",
    "from catalyst.dl.runner import SupervisedRunner\n",
    "from catalyst.dl.callbacks import EarlyStoppingCallback, AccuracyCallback, F1ScoreCallback, ConfusionMatrixCallback, MixupCallback\n",
    "from catalyst.dl.core.state import RunnerState\n",
    "from catalyst.dl.core import MetricCallback\n",
    "from catalyst.dl.callbacks import CriterionCallback\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for random patch augmentation\n",
    "class RandomPatch(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, image):\n",
    "        image_aug = image\n",
    "        xs = np.random.randint(image_aug.shape[1], size=8)\n",
    "        ys = np.random.randint(image_aug.shape[0], size=8)\n",
    "        ws = np.random.randint(60, size=8)\n",
    "        hs = np.random.randint(60, size=8)\n",
    "        cs = np.random.randint(255, size=8)\n",
    "\n",
    "        for x, y, w, h, c in zip(xs, ys, ws, hs, cs):\n",
    "            cv2.rectangle(image_aug, (x, y), (x + w, y + h), (int(c), int(c), int(c)), -1)\n",
    "\n",
    "        return image_aug\n",
    "    \n",
    "def crop_image_from_gray(img, tol=7):\n",
    "    if img.ndim == 2:\n",
    "        mask = img > tol\n",
    "        return img[np.ix_(mask.any(1), mask.any(0))]\n",
    "    elif img.ndim == 3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img > tol\n",
    "\n",
    "        check_shape = img[:, :, 0][np.ix_(mask.any(1), mask.any(0))].shape[0]\n",
    "        if (check_shape == 0):  # image is too dark so that we crop out everything,\n",
    "            return img  # return original image\n",
    "        else:\n",
    "            img1 = img[:, :, 0][np.ix_(mask.any(1), mask.any(0))]\n",
    "            img2 = img[:, :, 1][np.ix_(mask.any(1), mask.any(0))]\n",
    "            img3 = img[:, :, 2][np.ix_(mask.any(1), mask.any(0))]\n",
    "            #         print(img1.shape,img2.shape,img3.shape)\n",
    "            img = np.stack([img1, img2, img3], axis=-1)\n",
    "        #         print(img.shape)\n",
    "        return img\n",
    "\n",
    "\n",
    "def preprocessing(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = crop_image_from_gray(image)\n",
    "    blurred = cv2.GaussianBlur(image, (0, 0), 10)\n",
    "    image = cv2.addWeighted(image, 4, blurred, -4, 128)\n",
    "    return cv2.resize(image, (224, 224))\n",
    "\n",
    "\n",
    "# Convert dataset file into proper form for training\n",
    "class DiabeticDataset(Dataset):\n",
    "    def __init__(self, dataset_path, labels, ids, transform, albumentations_tr, shuffle=True):\n",
    "        self.labels = labels\n",
    "        self.ids = ids\n",
    "        self.shuffle = shuffle\n",
    "        self.dataset_path = dataset_path\n",
    "        self.albumentations_tr = albumentations_tr\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        imid = self.ids[index]\n",
    "        image = cv2.imread(os.path.join(self.dataset_path, imid + '.png'))\n",
    "        image = preprocessing(image)\n",
    "\n",
    "        if self.albumentations_tr:\n",
    "            augmented = self.albumentations_tr(image=image)\n",
    "            image = augmented['image']\n",
    "        # cv2.imwrite(example[0] + '.png', image)\n",
    "        image = image / 255.\n",
    "        # image = np.expand_dims(image, axis=2)\n",
    "        target = self.labels[index]\n",
    "        return torch.from_numpy(image.transpose((2, 0, 1))).float(), torch.tensor(np.expand_dims(target,0)).float()\n",
    "    \n",
    "def calculate_weights(dataset):\n",
    "    \"\"\"\n",
    "    Calculate weights of classes in dataset\n",
    "    :param labels: list of files with parsed data\n",
    "    :return: weights of classes\n",
    "    \"\"\"\n",
    "\n",
    "    classes = {'NoDR': 0, 'Mild': 0, 'Moderate': 0, 'Severe': 0, 'Proliferative': 0}\n",
    "    seq_type = []\n",
    "    seq_weight = []\n",
    "    for example in dataset:\n",
    "        stage = example[1]\n",
    "        if stage == '0':\n",
    "            classes['NoDR'] += 1\n",
    "            seq_type.append('NoDR')\n",
    "        elif stage == '1':\n",
    "            classes['Mild'] += 1\n",
    "            seq_type.append('Mild')\n",
    "        elif stage == '2':\n",
    "            classes['Moderate'] += 1\n",
    "            seq_type.append('Moderate')\n",
    "        elif stage == '3':\n",
    "            classes['Severe'] += 1\n",
    "            seq_type.append('Severe')\n",
    "        elif stage == '4':\n",
    "            classes['Proliferative'] += 1\n",
    "            seq_type.append('Proliferative')\n",
    "\n",
    "    for i in classes.keys():\n",
    "        classes[i] = 1 / classes[i]\n",
    "\n",
    "    for type_img in seq_type:\n",
    "        seq_weight.append(classes[type_img])\n",
    "\n",
    "    return seq_weight\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "class CutmixCallback(CriterionCallback):\n",
    "    \"\"\"\n",
    "    Callback to do mixup augmentation.\n",
    "    Paper: https://arxiv.org/abs/1710.09412\n",
    "    Note:\n",
    "        MixupCallback is inherited from CriterionCallback and\n",
    "        does its work.\n",
    "        You may not use them together.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        fields: List[str] = (\"features\", ),\n",
    "        alpha=1.0,\n",
    "        on_train_only=True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            fields (List[str]): list of features which must be affected.\n",
    "            alpha (float): beta distribution a=b parameters.\n",
    "                Must be >=0. The more alpha closer to zero\n",
    "                the less effect of the mixup.\n",
    "            on_train_only (bool): Apply to train only.\n",
    "                As the mixup use the proxy inputs, the targets are also proxy.\n",
    "                We are not interested in them, are we?\n",
    "                So, if on_train_only is True, use a standard output/metric\n",
    "                for validation.\n",
    "        \"\"\"\n",
    "        assert len(fields) > 0, \\\n",
    "            \"At least one field for MixupCallback is required\"\n",
    "        assert alpha >= 0, \"alpha must be>=0\"\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.on_train_only = on_train_only\n",
    "        self.fields = fields\n",
    "        self.alpha = alpha\n",
    "        self.lam = 1\n",
    "        self.index = None\n",
    "        self.is_needed = True\n",
    "\n",
    "    def on_loader_start(self, state: RunnerState):\n",
    "        self.is_needed = not self.on_train_only or \\\n",
    "            state.loader_name.startswith(\"train\")\n",
    "\n",
    "    def on_batch_start(self, state: RunnerState):\n",
    "        if not self.is_needed:\n",
    "            return\n",
    "\n",
    "        if self.alpha > 0:\n",
    "            self.lam = np.random.beta(self.alpha, self.alpha)\n",
    "        else:\n",
    "            self.lam = 1\n",
    "\n",
    "        self.index = torch.randperm(state.input[self.fields[0]].shape[0])\n",
    "        self.index.to(state.device)\n",
    "\n",
    "        for f in self.fields:\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(state.input[f].size(), self.lam)\n",
    "            state.input[f][:, :, bbx1:bbx2, bby1:bby2] = state.input[f][self.index, :, bbx1:bbx2, bby1:bby2]\n",
    "            \n",
    "\n",
    "    def _compute_loss(self, state: RunnerState, criterion):\n",
    "        if not self.is_needed:\n",
    "            return super()._compute_loss(state, criterion)\n",
    "\n",
    "        pred = state.output[self.output_key]\n",
    "        y_a = state.input[self.input_key]\n",
    "        y_b = state.input[self.input_key][self.index]\n",
    "\n",
    "        loss = self.lam * criterion(pred, y_a) + \\\n",
    "            (1 - self.lam) * criterion(pred, y_b)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_weighted_kappa(\n",
    "    outputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    threshold: float = None,\n",
    "    activation: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        outputs (torch.Tensor): A list of predicted elements\n",
    "        targets (torch.Tensor):  A list of elements that are to be predicted\n",
    "        activation (str): An torch.nn activation applied to the outputs.\n",
    "            Must be one of [\"none\", \"Sigmoid\", \"Softmax2d\"]\n",
    "    Returns:\n",
    "        float: quadratic kappa score\n",
    "    \"\"\"\n",
    "    outputs = outputs.detach().cpu().numpy()\n",
    "    targets = targets.detach().cpu().numpy()\n",
    "    outputs_clipped = list()\n",
    "    outputs_clipped = np.rint(outputs)\n",
    "    outputs_clipped[outputs_clipped<0] = 0\n",
    "    outputs_clipped[outputs_clipped>4] = 4\n",
    "    #for o in outputs:\n",
    "    #    if o <= 0.5:\n",
    "    #        outputs_clipped.append(0)\n",
    "    #    if 0.5 > o <= 1.5:\n",
    "    #        outputs_clipped.append(1)\n",
    "    #    if 1.5 < o <= 2.5:\n",
    "    #        outputs_clipped.append(2)\n",
    "    #    if 2.5 < o <= 3.5:\n",
    "    #        outputs_clipped.append(3)\n",
    "    #    if o > 3.5:\n",
    "    #        outputs_clipped.append(4)      \n",
    "    #simple clip of outputs\n",
    "    score = cohen_kappa_score(outputs_clipped, targets, weights='quadratic')\n",
    "    return score\n",
    "class QuadraticKappScoreMetricCallback(MetricCallback):\n",
    "    \"\"\"\n",
    "    F1 score metric callback.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_key: str = \"targets\",\n",
    "        output_key: str = \"logits\",\n",
    "        prefix: str = \"qkappa_score\",\n",
    "        activation: str = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_key (str): input key to use for iou calculation\n",
    "                specifies our ``y_true``.\n",
    "            output_key (str): output key to use for iou calculation;\n",
    "                specifies our ``y_pred``\n",
    "            activation (str): An torch.nn activation applied to the outputs.\n",
    "                Must be one of ['none', 'Sigmoid', 'Softmax2d']\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(\n",
    "            prefix=prefix,\n",
    "            metric_fn=quadratic_weighted_kappa,\n",
    "            input_key=input_key,\n",
    "            output_key=output_key,\n",
    "            activation=activation\n",
    "        )\n",
    "        \n",
    "def mean_squared_error_callback(\n",
    "    outputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    threshold: float = None,\n",
    "    activation: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        outputs (torch.Tensor): A list of predicted elements\n",
    "        targets (torch.Tensor):  A list of elements that are to be predicted\n",
    "        activation (str): An torch.nn activation applied to the outputs.\n",
    "            Must be one of [\"none\", \"Sigmoid\", \"Softmax2d\"]\n",
    "    Returns:\n",
    "        float: quadratic kappa score\n",
    "    \"\"\"\n",
    "\n",
    "    outputs = outputs.cpu().detach().numpy()\n",
    "    score = mean_squared_error(outputs, targets.detach().cpu().numpy())\n",
    "    return score\n",
    "class MSECallback(MetricCallback):\n",
    "    \"\"\"\n",
    "    F1 score metric callback.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_key: str = \"targets\",\n",
    "        output_key: str = \"logits\",\n",
    "        prefix: str = \"mse_score\",\n",
    "        activation: str = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_key (str): input key to use for iou calculation\n",
    "                specifies our ``y_true``.\n",
    "            output_key (str): output key to use for iou calculation;\n",
    "                specifies our ``y_pred``\n",
    "            activation (str): An torch.nn activation applied to the outputs.\n",
    "                Must be one of ['none', 'Sigmoid', 'Softmax2d']\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(\n",
    "            prefix=prefix,\n",
    "            metric_fn=mean_squared_error_callback,\n",
    "            input_key=input_key,\n",
    "            output_key=output_key,\n",
    "            activation=activation\n",
    "        )\n",
    "def mean_absolute_error_callback(\n",
    "    outputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    threshold: float = None,\n",
    "    activation: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        outputs (torch.Tensor): A list of predicted elements\n",
    "        targets (torch.Tensor):  A list of elements that are to be predicted\n",
    "        activation (str): An torch.nn activation applied to the outputs.\n",
    "            Must be one of [\"none\", \"Sigmoid\", \"Softmax2d\"]\n",
    "    Returns:\n",
    "        float: quadratic kappa score\n",
    "    \"\"\"\n",
    "\n",
    "    outputs = outputs.cpu().detach().numpy()\n",
    "    score = mean_absolute_error(outputs, targets.detach().cpu().numpy())\n",
    "    return score\n",
    "class MAECallback(MetricCallback):\n",
    "    \"\"\"\n",
    "    F1 score metric callback.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_key: str = \"targets\",\n",
    "        output_key: str = \"logits\",\n",
    "        prefix: str = \"mae_score\",\n",
    "        activation: str = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_key (str): input key to use for iou calculation\n",
    "                specifies our ``y_true``.\n",
    "            output_key (str): output key to use for iou calculation;\n",
    "                specifies our ``y_pred``\n",
    "            activation (str): An torch.nn activation applied to the outputs.\n",
    "                Must be one of ['none', 'Sigmoid', 'Softmax2d']\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(\n",
    "            prefix=prefix,\n",
    "            metric_fn=mean_absolute_error_callback,\n",
    "            input_key=input_key,\n",
    "            output_key=output_key,\n",
    "            activation=activation\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_train(p=1): \n",
    "    return Compose([OneOf([\n",
    "                        HorizontalFlip(), \n",
    "                        VerticalFlip(), \n",
    "                        RandomRotate90(), \n",
    "                        Transpose()],p=0.25)\n",
    "                    ], p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 12\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "w, d, s, p = 1.0, 1.0, 224, 0.2\n",
    "blocks_args, global_params = efficientnet(\n",
    "    width_coefficient=w, depth_coefficient=d, dropout_rate=p, image_size=s)\n",
    "out_channels = round_filters(1280, global_params)\n",
    "model._fc = nn.Linear(out_channels, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Linear(in_features=1280, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained = torch.load('logs/efficient_net_log_strong_aug_wd01/checkpoints/best.pth')\n",
    "model.load_state_dict(pretrained['model_state_dict'])\n",
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/test.csv')\n",
    "submit = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_id, imdir):\n",
    "    image = cv2.imread(os.path.join(imdir, image_id + '.png'))\n",
    "    image = preprocessing(image)\n",
    "    image = image / 225.0\n",
    "    image = np.rollaxis(image, -1)    \n",
    "    image = np.expand_dims(image, 0)\n",
    "    image = torch.tensor(image, dtype=torch.float32).cuda()\n",
    "    return image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 431/1928 [00:41<01:39, 14.98it/s]"
     ]
    }
   ],
   "source": [
    "predicted_reg  = list()\n",
    "with torch.no_grad():\n",
    "    for i, name in tqdm(enumerate(submit['id_code']), total=len(submit['id_code'])):\n",
    "        image = preprocess_image(name, '../data/test')\n",
    "        predicted_reg += [model(image)[0][0].cpu().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_reg = np.array(predicted_reg)\n",
    "predicted_reg[predicted_reg<0] = 0\n",
    "predicted_reg[predicted_reg>4] = 4\n",
    "predicted_clipped = list()\n",
    "for idx in range(len(predicted_reg)):\n",
    "    if predicted_reg[idx]<0.5:\n",
    "        predicted_clipped.append(0)\n",
    "    elif  predicted_reg[idx]>=0.5 and predicted_reg[idx]<1.5:\n",
    "        predicted_clipped.append(1)\n",
    "    elif  predicted_reg[idx]>=1.5 and predicted_reg[idx]<2.5:\n",
    "        predicted_clipped.append(2)\n",
    "    elif  predicted_reg[idx]>=2.5 and predicted_reg[idx]<3.5:\n",
    "        predicted_clipped.append(3)\n",
    "    elif  predicted_reg[idx]>=3.5:\n",
    "        predicted_clipped.append(4)\n",
    "assert(len(predicted_clipped)==len(predicted_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([123.,   0., 580.,   0.,   0., 971.,   0., 253.,   0.,   1.]),\n",
       " array([0. , 0.4, 0.8, 1.2, 1.6, 2. , 2.4, 2.8, 3.2, 3.6, 4. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAD8RJREFUeJzt3X+s3Xddx/Hni3Xjp9D9uOBsK3eERp1EZN7MIgkhjCDbyLrEzcwo65aaJooCzgQKMS6if4zEMEDNSGVop4hbBnF1G5K5jRD/WOVujB+j4Oqc23WTXthWwIlYefvH+ZRd7m57T++5Pafd5/lIbu73+/l+zvm8+2m/93W/n3O+p6kqJEn9edakC5AkTYYBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASerUmkkXcDinnXZaTU9PT7oMSTqu3H333d+oqqnl+i0bAEk+CrwZ2FdVr2htpwDXA9PAg8AvV9XjSQJ8EDgPeBK4rKruaY/ZAvxee9o/qqqdy409PT3N7Ozsct0kSQsk+fdh+g2zBPSXwJsWtW0Hbq+qjcDtbR/gXGBj+9oGXNOKOQW4Evh54GzgyiQnD1OgJOnoWDYAquqzwGOLmjcDB3+D3wlcuKD9uhq4C1ib5HTgF4HbquqxqnocuI2nh4okaYxW+iLwS6rqUYD2/cWtfR3w8IJ+c63tUO2SpAlZ7XcBZYm2Okz7058g2ZZkNsns/Pz8qhYnSXrKSgPg621ph/Z9X2ufAzYs6LceeOQw7U9TVTuqaqaqZqamln0RW5K0QisNgF3Alra9BbhpQfulGdgE7G9LRJ8G3pjk5Pbi7xtbmyRpQoZ5G+jHgdcBpyWZY/BunquAG5JsBR4CLm7db2XwFtC9DN4GejlAVT2W5A+Bz7V+762qxS8sS5LGKMfyfwk5MzNT3gcgSUcmyd1VNbNcPz8KQpI6dUx/FIR0LJvefstExn3wqvMnMq6eebwCkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHVqpABI8jtJ7kvy5SQfT/KcJGck2Z3k/iTXJzmp9X1229/bjk+vxh9AkrQyKw6AJOuAtwEzVfUK4ATgEuB9wNVVtRF4HNjaHrIVeLyqXg5c3fpJkiZk1CWgNcBzk6wBngc8CrweuLEd3wlc2LY3t33a8XOSZMTxJUkrtOIAqKr/AP4YeIjBD/79wN3AE1V1oHWbA9a17XXAw+2xB1r/Uxc/b5JtSWaTzM7Pz6+0PEnSMkZZAjqZwW/1ZwA/BjwfOHeJrnXwIYc59lRD1Y6qmqmqmampqZWWJ0laxihLQG8A/q2q5qvqf4FPAr8ArG1LQgDrgUfa9hywAaAdfxHw2AjjS5JGMEoAPARsSvK8tpZ/DvAV4E7gotZnC3BT297V9mnH76iqp10BSJLGY5TXAHYzeDH3HuBL7bl2AO8Crkiyl8Ea/7XtIdcCp7b2K4DtI9QtSRrRmuW7HFpVXQlcuaj5AeDsJfp+F7h4lPEkSavHO4ElqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTIwVAkrVJbkzy1SR7krw6ySlJbktyf/t+cuubJB9KsjfJF5OctTp/BEnSSox6BfBB4B+q6ieBVwJ7gO3A7VW1Ebi97QOcC2xsX9uAa0YcW5I0ghUHQJIXAq8FrgWoqu9V1RPAZmBn67YTuLBtbwauq4G7gLVJTl9x5ZKkkYxyBfAyYB74iySfT/KRJM8HXlJVjwK07y9u/dcBDy94/FxrkyRNwCgBsAY4C7imql4F/BdPLfcsJUu01dM6JduSzCaZnZ+fH6E8SdLhjBIAc8BcVe1u+zcyCISvH1zaad/3Lei/YcHj1wOPLH7SqtpRVTNVNTM1NTVCeZKkw1lxAFTVfwIPJ/mJ1nQO8BVgF7CltW0Bbmrbu4BL27uBNgH7Dy4VSZLGb82Ij/9t4GNJTgIeAC5nECo3JNkKPARc3PreCpwH7AWebH0lSRMyUgBU1b3AzBKHzlmibwFvHWU8Hd709lsmNvaDV50/sbElrYx3AktSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnq1MgBkOSEJJ9PcnPbPyPJ7iT3J7k+yUmt/dltf287Pj3q2JKklVuNK4C3A3sW7L8PuLqqNgKPA1tb+1bg8ap6OXB16ydJmpCRAiDJeuB84CNtP8DrgRtbl53AhW17c9unHT+n9ZckTcCoVwAfAN4JfL/tnwo8UVUH2v4csK5trwMeBmjH97f+PyTJtiSzSWbn5+dHLE+SdCgrDoAkbwb2VdXdC5uX6FpDHHuqoWpHVc1U1czU1NRKy5MkLWPNCI99DXBBkvOA5wAvZHBFsDbJmvZb/nrgkdZ/DtgAzCVZA7wIeGyE8SVJI1jxFUBVvbuq1lfVNHAJcEdV/SpwJ3BR67YFuKlt72r7tON3VNXTrgAkSeNxNO4DeBdwRZK9DNb4r23t1wKntvYrgO1HYWxJ0pBGWQL6gar6DPCZtv0AcPYSfb4LXLwa40mSRuedwJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjq1ZtIFSDp+TG+/ZSLjPnjV+RMZ95nOKwBJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUqRUHQJINSe5MsifJfUne3tpPSXJbkvvb95Nbe5J8KMneJF9MctZq/SEkSUdulCuAA8DvVtVPAZuAtyY5E9gO3F5VG4Hb2z7AucDG9rUNuGaEsSVJI1pxAFTVo1V1T9v+NrAHWAdsBna2bjuBC9v2ZuC6GrgLWJvk9BVXLkkayaq8BpBkGngVsBt4SVU9CoOQAF7cuq0DHl7wsLnWJkmagJEDIMkLgE8A76iqbx2u6xJttcTzbUsym2R2fn5+1PIkSYcwUgAkOZHBD/+PVdUnW/PXDy7ttO/7WvscsGHBw9cDjyx+zqraUVUzVTUzNTU1SnmSpMMY5V1AAa4F9lTV+xcc2gVsadtbgJsWtF/a3g20Cdh/cKlIkjR+o3wa6GuAtwBfSnJva3sPcBVwQ5KtwEPAxe3YrcB5wF7gSeDyEcaWJI1oxQFQVf/E0uv6AOcs0b+At650PEnS6vJOYEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1apRPAz3mTW+/ZSLjPnjV+RMZV5KOhFcAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0aewAkeVOSryXZm2T7uMeXJA2MNQCSnAD8GXAucCbwK0nOHGcNkqSBcV8BnA3sraoHqup7wN8Cm8dcgySJ8QfAOuDhBftzrU2SNGZrxjxelmirH+qQbAO2td3vJPnaCOOdBnxjhMevSN63bJeJ1DWEFdc1xJ95FM+4+RqF/75W3TNuvoCXDtNp3AEwB2xYsL8eeGRhh6raAexYjcGSzFbVzGo812qyriNjXUfGuo5Mz3WNewnoc8DGJGckOQm4BNg15hokSYz5CqCqDiT5LeDTwAnAR6vqvnHWIEkaGPcSEFV1K3DrmIZblaWko8C6jox1HRnrOjLd1pWqWr6XJOkZx4+CkKROHfcBsNxHSyR5dpLr2/HdSaaPkbouSzKf5N729etjquujSfYl+fIhjifJh1rdX0xy1jFS1+uS7F8wX78/pro2JLkzyZ4k9yV5+xJ9xj5nQ9Y19jlL8pwk/5zkC62uP1iiz9jPySHrmtQ5eUKSzye5eYljR3euquq4/WLwQvK/Ai8DTgK+AJy5qM9vAh9u25cA1x8jdV0G/OkE5uy1wFnAlw9x/DzgUwzu2dgE7D5G6nodcPME5ut04Ky2/SPAvyzxdzn2ORuyrrHPWZuDF7TtE4HdwKZFfSZxTg5T16TOySuAv1nq7+poz9XxfgUwzEdLbAZ2tu0bgXOSLHVD2rjrmoiq+izw2GG6bAauq4G7gLVJTj8G6pqIqnq0qu5p298G9vD0u9fHPmdD1jV2bQ6+03ZPbF+LX2gc+zk5ZF1jl2Q9cD7wkUN0OapzdbwHwDAfLfGDPlV1ANgPnHoM1AXwS23J4MYkG5Y4PgnH8sd1vLpdwn8qyU+Pe/B2+f0qBr89LjTROTtMXTCBOWtLGvcC+4DbquqQ8zXGc3KYumD85+QHgHcC3z/E8aM6V8d7ACz70RJD9lltw4z598B0Vf0M8I88lfKTNon5GsY9wEur6pXAnwB/N87Bk7wA+ATwjqr61uLDSzxkLHO2TF0TmbOq+r+q+lkGd/qfneQVi7pMZL6GqGus52SSNwP7quruw3Vbom3V5up4D4BlP1piYZ8ka4AXcfSXGob5yItvVtX/tN0/B37uKNc0rGHmdOyq6lsHL+FrcC/JiUlOG8fYSU5k8EP2Y1X1ySW6TGTOlqtrknPWxnwC+AzwpkWHJnFOLlvXBM7J1wAXJHmQwTLx65P89aI+R3WujvcAGOajJXYBW9r2RcAd1V5RmWRdi9aIL2Cwhnss2AVc2t7ZsgnYX1WPTrqoJD96cO0zydkM/u1+cwzjBrgW2FNV7z9Et7HP2TB1TWLOkkwlWdu2nwu8Afjqom5jPyeHqWvc52RVvbuq1lfVNIOfEXdU1a8t6nZU52rsdwKvpjrER0skeS8wW1W7GJwkf5VkL4PkvOQYqettSS4ADrS6LjvadQEk+TiDd4eclmQOuJLBC2JU1YcZ3KV9HrAXeBK4/Bip6yLgN5IcAP4buGQMQQ6D39LeAnyprR8DvAf48QW1TWLOhqlrEnN2OrAzg//86VnADVV186TPySHrmsg5udg458o7gSWpU8f7EpAkaYUMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOvX/is+OWRR4uOEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(predicted_clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_submission = pd.read_csv('../data/submission_from_kaggle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['diagnosis'] = predicted_clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.58340919],\n",
       "       [0.58340919, 1.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(submit['diagnosis'], public_submission['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['diagnosis_public_kernel']= public_submission['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>diagnosis</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diagnosis_public_kernel</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>251.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "diagnosis                    0      1      2      3     4\n",
       "diagnosis_public_kernel                                  \n",
       "0                        251.0   71.0    NaN    NaN   NaN\n",
       "1                         45.0  129.0   18.0    NaN   NaN\n",
       "2                         11.0  181.0  762.0  128.0   NaN\n",
       "3                          NaN    4.0   89.0  191.0  16.0\n",
       "4                          NaN    NaN    NaN   15.0  17.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.groupby(['diagnosis_public_kernel', 'diagnosis']).size().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>diagnosis</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diagnosis_public_kernel</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>236.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "diagnosis                    0      1      2      3     4\n",
       "diagnosis_public_kernel                                  \n",
       "0                        236.0   86.0    NaN    NaN   NaN\n",
       "1                         40.0  142.0   10.0    NaN   NaN\n",
       "2                         10.0  346.0  679.0   47.0   NaN\n",
       "3                          NaN    4.0  175.0  114.0   7.0\n",
       "4                          NaN    NaN    1.0   17.0  14.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.groupby(['diagnosis_public_kernel', 'diagnosis']).size().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
