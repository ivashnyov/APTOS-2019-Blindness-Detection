INFO: 2019-07-12 12:56:40.717292: Train started
INFO: 2019-07-12 12:56:40.721383: Squeezenet with Adam optimizer, LR=1e-4, batch_size=32, epochs=150
INFO: 2019-07-12 12:59:52.047598: Epoch: 0/150 Step: 30/97 Loss: 1.0061812500158944
INFO: 2019-07-12 13:03:08.169108: Epoch: 0/150 Step: 60/97 Loss: 0.8236112554868064
INFO: 2019-07-12 13:06:21.143538: Epoch: 0/150 Step: 90/97 Loss: 0.7238911122083664
INFO: 2019-07-12 13:08:54.797021: Epoch: 20 val loss : 0.8310505712733549; val acc: 0.7003676295280457
INFO: 2019-07-12 13:08:54.803332: Kappa :
 0.7816244959831238
INFO: 2019-07-12 13:08:54.810521: Epoch time: 734.09
INFO: 2019-07-12 13:12:15.803843: Epoch: 1/150 Step: 30/97 Loss: 0.9199115842580794
INFO: 2019-07-12 13:15:25.534054: Epoch: 1/150 Step: 60/97 Loss: 0.712460398674011
INFO: 2019-07-12 13:18:48.372464: Epoch: 1/150 Step: 90/97 Loss: 0.6571782797574997
INFO: 2019-07-12 13:21:20.823190: Epoch: 21 val loss : 0.7244344599106732; val acc: 0.7316176295280457
INFO: 2019-07-12 13:21:20.828665: Kappa :
 0.8111247420310974
INFO: 2019-07-12 13:21:20.835102: Epoch time: 745.83
INFO: 2019-07-12 13:24:35.610129: Epoch: 2/150 Step: 30/97 Loss: 0.8513834148645401
INFO: 2019-07-12 13:27:47.661150: Epoch: 2/150 Step: 60/97 Loss: 0.7098015864690145
INFO: 2019-07-12 13:31:10.941408: Epoch: 2/150 Step: 90/97 Loss: 0.6329184899727504
INFO: 2019-07-12 13:33:41.992820: Epoch: 22 val loss : 0.641909238170175; val acc: 0.75
INFO: 2019-07-12 13:33:42.003039: Kappa :
 0.8047055006027222
INFO: 2019-07-12 13:33:42.016124: Epoch time: 740.96
INFO: 2019-07-12 13:36:50.610502: Epoch: 3/150 Step: 30/97 Loss: 0.7752796739339828
INFO: 2019-07-12 13:40:12.656743: Epoch: 3/150 Step: 60/97 Loss: 0.6222895542780559
INFO: 2019-07-12 13:43:41.261006: Epoch: 3/150 Step: 90/97 Loss: 0.5852587272723515
INFO: 2019-07-12 13:46:07.571585: Epoch: 23 val loss : 0.6378830496002647; val acc: 0.7665441036224365
INFO: 2019-07-12 13:46:07.778916: Kappa :
 0.7819132208824158
INFO: 2019-07-12 13:46:07.783315: Epoch time: 745.50
INFO: 2019-07-12 13:49:10.352862: Epoch: 4/150 Step: 30/97 Loss: 0.7481630156437556
INFO: 2019-07-12 13:52:18.325124: Epoch: 4/150 Step: 60/97 Loss: 0.6239101151625314
INFO: 2019-07-12 13:55:51.521066: Epoch: 4/150 Step: 90/97 Loss: 0.5731678724288942
INFO: 2019-07-12 13:58:23.730823: Epoch: 24 val loss : 0.6055621417129741; val acc: 0.7738970518112183
INFO: 2019-07-12 13:58:23.738394: Kappa :
 0.7754386067390442
INFO: 2019-07-12 13:58:23.743459: Epoch time: 735.63
INFO: 2019-07-12 14:01:36.771002: Epoch: 5/150 Step: 30/97 Loss: 0.7298525631427767
INFO: 2019-07-12 14:04:53.623399: Epoch: 5/150 Step: 60/97 Loss: 0.6144832283258439
INFO: 2019-07-12 14:08:13.634126: Epoch: 5/150 Step: 90/97 Loss: 0.5535772224267324
INFO: 2019-07-12 14:10:44.079588: Epoch: 25 val loss : 0.614275443203309; val acc: 0.7738970518112183
INFO: 2019-07-12 14:10:44.085486: Kappa :
 0.7950278520584106
INFO: 2019-07-12 14:10:44.090573: Epoch time: 740.13
INFO: 2019-07-12 14:14:08.352119: Epoch: 6/150 Step: 30/97 Loss: 0.7091251373291014
INFO: 2019-07-12 14:17:22.833243: Epoch: 6/150 Step: 60/97 Loss: 0.5641220827897391
INFO: 2019-07-12 14:20:48.816083: Epoch: 6/150 Step: 90/97 Loss: 0.537336395184199
INFO: 2019-07-12 14:23:15.948089: Epoch: 26 val loss : 0.5981817613629734; val acc: 0.7702205777168274
INFO: 2019-07-12 14:23:15.952340: Kappa :
 0.7853201627731323
INFO: 2019-07-12 14:23:15.956246: Epoch time: 751.59
INFO: 2019-07-12 14:26:41.778433: Epoch: 7/150 Step: 30/97 Loss: 0.6848857353130976
INFO: 2019-07-12 14:30:12.925609: Epoch: 7/150 Step: 60/97 Loss: 0.5547504504521688
INFO: 2019-07-12 14:33:43.280579: Epoch: 7/150 Step: 90/97 Loss: 0.525632847348849
INFO: 2019-07-12 14:36:24.565893: Epoch: 27 val loss : 0.6022971167283899; val acc: 0.7702205777168274
INFO: 2019-07-12 14:36:24.571387: Kappa :
 0.7980425953865051
INFO: 2019-07-12 14:36:24.576290: Epoch time: 788.39
INFO: 2019-07-12 14:39:57.781914: Epoch: 8/150 Step: 30/97 Loss: 0.6825085252523422
INFO: 2019-07-12 14:43:35.352256: Epoch: 8/150 Step: 60/97 Loss: 0.5810268541177113
INFO: 2019-07-12 14:47:21.232792: Epoch: 8/150 Step: 90/97 Loss: 0.5168470134337744
INFO: 2019-07-12 14:49:59.851638: Epoch: 28 val loss : 0.6031424473313725; val acc: 0.7720588445663452
INFO: 2019-07-12 14:49:59.858782: Kappa :
 0.7950510382652283
INFO: 2019-07-12 14:49:59.863809: Epoch time: 815.05
INFO: 2019-07-12 14:53:33.128869: Epoch: 9/150 Step: 30/97 Loss: 0.6624992281198503
INFO: 2019-07-12 14:56:55.621224: Epoch: 9/150 Step: 60/97 Loss: 0.5477088669935861
INFO: 2019-07-12 15:00:28.881605: Epoch: 9/150 Step: 90/97 Loss: 0.5240531067053478
INFO: 2019-07-12 15:03:07.516798: Epoch: 29 val loss : 0.6006946703966927; val acc: 0.7775735259056091
INFO: 2019-07-12 15:03:07.521003: Kappa :
 0.7927109003067017
INFO: 2019-07-12 15:03:07.524929: Epoch time: 787.44
INFO: 2019-07-12 15:06:37.532561: Epoch: 10/150 Step: 30/97 Loss: 0.6626503884792325
INFO: 2019-07-12 15:09:59.049168: Epoch: 10/150 Step: 60/97 Loss: 0.5383811275164286
INFO: 2019-07-12 15:13:15.322428: Epoch: 10/150 Step: 90/97 Loss: 0.5149183476964633
INFO: 2019-07-12 15:15:30.924976: Epoch: 30 val loss : 0.596182726761874; val acc: 0.7757353186607361
INFO: 2019-07-12 15:15:30.930113: Kappa :
 0.7923663854598999
INFO: 2019-07-12 15:15:30.938411: Epoch time: 743.20
INFO: 2019-07-12 15:18:40.046299: Epoch: 11/150 Step: 30/97 Loss: 0.6459360390901566
INFO: 2019-07-12 15:21:56.584846: Epoch: 11/150 Step: 60/97 Loss: 0.5317089398701986
INFO: 2019-07-12 15:25:21.265917: Epoch: 11/150 Step: 90/97 Loss: 0.505111038684845
INFO: 2019-07-12 15:27:47.543289: Epoch: 31 val loss : 0.6021161780637854; val acc: 0.7830882668495178
INFO: 2019-07-12 15:27:47.551760: Kappa :
 0.8021190762519836
INFO: 2019-07-12 15:27:47.559741: Epoch time: 736.40
INFO: 2019-07-12 15:31:06.549924: Epoch: 12/150 Step: 30/97 Loss: 0.6627841492493945
INFO: 2019-07-12 15:34:19.392642: Epoch: 12/150 Step: 60/97 Loss: 0.5406347970167795
INFO: 2019-07-12 15:37:30.426758: Epoch: 12/150 Step: 90/97 Loss: 0.49559594591458633
INFO: 2019-07-12 15:40:02.035921: Epoch: 32 val loss : 0.6014947838643018; val acc: 0.7702205777168274
INFO: 2019-07-12 15:40:02.040141: Kappa :
 0.7903414964675903
INFO: 2019-07-12 15:40:02.043943: Epoch time: 734.19
INFO: 2019-07-12 15:43:06.726537: Epoch: 13/150 Step: 30/97 Loss: 0.6446857422590255
INFO: 2019-07-12 15:46:14.823151: Epoch: 13/150 Step: 60/97 Loss: 0.5302163978417714
INFO: 2019-07-12 15:49:21.447666: Epoch: 13/150 Step: 90/97 Loss: 0.5018402968843777
INFO: 2019-07-12 16:14:26.839327: Train started
INFO: 2019-07-12 16:14:26.844167: Squeezenet with Adam optimizer, LR=1e-4, batch_size=32, epochs=150
ERROR: 2019-07-12 16:14:35.696063: Error: 'tuple' object has no attribute 'log_softmax'
INFO: 2019-07-12 16:16:24.102612: Train started
INFO: 2019-07-12 16:16:24.107268: Squeezenet with Adam optimizer, LR=1e-4, batch_size=32, epochs=150
